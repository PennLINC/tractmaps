{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df65919-bb00-4881-8789-0292aee309af",
   "metadata": {},
   "source": [
    "# Random forest classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f73dd1b-3876-48b5-a068-eccaf275d3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..') # Move one directory up to access 'code' directory\n",
    "from data_prep import tm_parcellate\n",
    "from utils import tm_utils\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d404505-2209-47ee-8074-c1b96ac3905c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "384f2a92-baa0-471a-b8d8-3b2e408136d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CORTICAL FEATURES DATA ###\n",
    "# analysis = 'cortex'\n",
    "# data = pd.read_csv('./inputs/tracts_maps_Glasser.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a43f0a6-efc1-458c-be91-16d49f3871fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEUROSYNTH 123 COGNITIVE TERMS ###\n",
    "analysis = 'neurosynth'\n",
    "data_root = '/Users/joelleba/PennLINC/tractmaps/data/neurosynth_annotations/'\n",
    "data = pd.read_csv(f'{data_root}/glasser/glasser_tracts_neurosynth_123terms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebaf0a6a-4a0e-4fe9-938c-36436495e581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### NEUROSYNTH 11 cognitive categories ###\n",
    "# analysis = 'cogcategories'\n",
    "# data_root = '/Users/joelleba/PennLINC/tractmaps/data/neurosynth_annotations/'\n",
    "# data = pd.read_csv(f'{data_root}/glasser/glasser_tracts_neurosynth_11cogcategories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be6b65ba-4991-40fa-af6d-39988d52463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up inputs\n",
    "maps_df = data.iloc[:, 59:]\n",
    "map_names = list(maps_df)\n",
    "glasser_maps = maps_df.to_dict(orient = 'list')\n",
    "glasser_maps = {key: np.array(value) for key, value in glasser_maps.items()} # store parcellated maps as dictionary of map_names and arrays\n",
    "glasser = tm_parcellate.get_glasser() # load glasser parcellation GIFTI images (lh, rh)\n",
    "nspins = 10000\n",
    "root = '/Users/joelleba/PennLINC/tractmaps'\n",
    "spins = tm_utils.load_data(f'{root}/data/nulls/tracts/tracts_{nspins}spins.pickle')\n",
    "testtype = 'onetailed' # goal is to determine whether empirical R2 is larger than null distribution of R2s\n",
    "threshold = 0.6 # threshold for binarization of tract probabilities data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a4575b2-022a-4bd9-8a0a-91bd5784d89c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder '/Users/joelleba/PennLINC/tractmaps/results/classification/neurosynth/' created.\n"
     ]
    }
   ],
   "source": [
    "# create results directory if it doesn't yet exist\n",
    "results_dir = f'{root}/results/classification/{analysis}/'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    print(f\"Folder '{results_dir}' created.\")\n",
    "else:\n",
    "    print(f\"Folder '{results_dir}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43193d94-297c-4b15-b423-2c92d922a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(cog_terms, tract_probs, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Feature Selection using Random Forest\n",
    "# Initialize a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the random forest on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Use SelectFromModel to select features based on feature importances\n",
    "sfm = SelectFromModel(rf, threshold=0.05)  # Adjust threshold as needed\n",
    "sfm.fit(X_train, y_train)\n",
    "\n",
    "# Transform the training and testing data to include only selected features\n",
    "X_train_selected = sfm.transform(X_train)\n",
    "X_test_selected = sfm.transform(X_test)\n",
    "\n",
    "# Step 3: Random Forest Classification with Selected Features\n",
    "# Initialize a new random forest classifier\n",
    "rf_selected = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the random forest on the training data with selected features\n",
    "rf_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predictions on the testing data\n",
    "y_pred = rf_selected.predict(X_test_selected)\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615d5f24-3229-43ad-b42e-61ae67d91927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Get feature importances from the random forest\n",
    "feature_importances = rf_selected.feature_importances_\n",
    "\n",
    "# Initialize an array to store feature importance values\n",
    "all_feature_importances = np.zeros(cog_terms.shape[1])\n",
    "\n",
    "# Set the feature importance values for selected features\n",
    "selected_indices = sfm.get_support(indices=True)\n",
    "all_feature_importances[selected_indices] = feature_importances\n",
    "\n",
    "# Reshape feature importance array to match the original shape of predictors matrix\n",
    "feature_importance_matrix = all_feature_importances.reshape(cog_terms.shape)\n",
    "\n",
    "# Create a heatmap of feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(feature_importance_matrix, cmap='viridis', annot=True, fmt=\".3f\", xticklabels=False)\n",
    "plt.xlabel('Predictor Index')\n",
    "plt.ylabel('Sample Index')\n",
    "plt.title('Feature Importance Heatmap')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tractmaps]",
   "language": "python",
   "name": "conda-env-tractmaps-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
